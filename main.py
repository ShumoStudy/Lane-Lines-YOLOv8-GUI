from ultralytics.yolo.engine.predictor import BasePredictor
from ultralytics.yolo.engine.results import Results
from ultralytics.yolo.utils import DEFAULT_CFG, LOGGER, SETTINGS, callbacks, ops
from ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box
from ultralytics.yolo.utils.torch_utils import smart_inference_mode
from ultralytics.yolo.utils.files import increment_path
from ultralytics.yolo.utils.checks import check_imshow
from ultralytics.yolo.cfg import get_cfg
from PySide6.QtWidgets import QApplication, QMainWindow, QFileDialog, QMenu
from PySide6.QtGui import QImage, QPixmap, QColor
from PySide6.QtCore import QTimer, QThread, Signal, QObject, QPoint, Qt
from ui.CustomMessageBox import MessageBox
from ui.home import Ui_MainWindow
from UIFunctions import *
from collections import defaultdict
from pathlib import Path
import numpy as np
import time
import json
import torch
import sys
import cv2
import os


class YoloPredictor(BasePredictor, QObject):
    yolo2main_pre_img = Signal(np.ndarray)       # åŽŸå§‹å›¾åƒä¿¡å·
    yolo2main_res_img = Signal(np.ndarray)       # æµ‹è¯•ç»“æžœä¿¡å·
    yolo2main_status_msg = Signal(str)           # æ£€æµ‹/æš‚åœ/åœæ­¢/æµ‹è¯•å®Œæˆ/é”™è¯¯æŠ¥å‘Šä¿¡å·
    yolo2main_fps = Signal(str)                  # å¸§çŽ‡ä¿¡å·
    yolo2main_labels = Signal(dict)              # æ£€æµ‹åˆ°çš„ç›®æ ‡ç»“æžœï¼ˆæ¯ä¸ªç±»åˆ«çš„æ•°é‡ï¼‰
    yolo2main_progress = Signal(int)             # å®Œæˆåº¦ä¿¡å·
    yolo2main_class_num = Signal(int)            # æ£€æµ‹åˆ°çš„ç±»åˆ«æ•°é‡ä¿¡å·
    yolo2main_target_num = Signal(int)           # æ£€æµ‹åˆ°çš„ç›®æ ‡æ•°é‡ä¿¡å·

    def __init__(self, cfg=DEFAULT_CFG, overrides=None): 
        super(YoloPredictor, self).__init__()       # è°ƒç”¨çˆ¶ç±»çš„æž„é€ å‡½æ•°ï¼Œç¡®ä¿ BasePredictor çš„åˆå§‹åŒ–ã€‚
        QObject.__init__(self)                      # è°ƒç”¨ QObject çš„æž„é€ å‡½æ•°ï¼Œç¡®ä¿å…¶å±žæ€§å’Œæ–¹æ³•å¯ç”¨ã€‚

        self.args = get_cfg(cfg, overrides)         # èŽ·å–é…ç½®å‚æ•°ï¼šself.args ä½¿ç”¨ get_cfg å‡½æ•°èŽ·å–é…ç½®å‚æ•°ï¼Œ
        # ä¼ é€’é»˜è®¤é…ç½® cfg å’Œå¯é€‰çš„è¦†ç›–é…ç½® overridesã€‚
        project = self.args.project or Path(SETTINGS['runs_dir']) / self.args.task      # project ç¡®å®šé¡¹ç›®è·¯å¾„ï¼Œ
        # ä½¿ç”¨ self.args.project æˆ–è€… SETTINGS['runs_dir'] å’Œä»»åŠ¡åç»„åˆæˆè·¯å¾„ã€‚
        name = f'{self.args.mode}'                  # name è®¾ç½®ä¸ºæ¨¡å¼åç§°ã€‚
        self.save_dir = increment_path(Path(project) / name, exist_ok=self.args.exist_ok)
        # self.save_dir é€šè¿‡ increment_path å‡½æ•°ç”Ÿæˆä¿å­˜ç›®å½•è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„å”¯ä¸€æ€§ï¼Œå¦‚æžœ self.args.exist_ok ä¸º Trueï¼Œåˆ™å…è®¸è¦†ç›–çŽ°æœ‰è·¯å¾„ã€‚
        self.done_warmup = False        #åˆå§‹åŒ–æš–æœºçŠ¶æ€ï¼šself.done_warmup è®¾ç½®ä¸º Falseï¼Œè¡¨ç¤ºæœªå®Œæˆæš–æœºã€‚
        if self.args.show:
            self.args.show = check_imshow(warn=True)
        # æ£€æŸ¥æ˜¾ç¤ºé€‰é¡¹ï¼šå¦‚æžœ self.args.show ä¸º Trueï¼Œè°ƒç”¨ check_imshow å‡½æ•°æ£€æŸ¥æ˜¯å¦å¯ä»¥æ˜¾ç¤ºå›¾åƒï¼Œå¹¶è®¾ç½® self.args.show ä¸ºæ£€æŸ¥ç»“æžœã€‚

        # GUI å‚æ•°
        self.used_model_name = None     # è¦ä½¿ç”¨çš„æ£€æµ‹æ¨¡åž‹åç§°
        self.new_model_name = None      # å®žæ—¶æ›´æ”¹çš„æ¨¡åž‹
        self.source = ''                # è¾“å…¥æº
        self.stop_dtc = False           # ç»ˆæ­¢æ£€æµ‹
        self.continue_dtc = True        # æš‚åœ
        self.save_res = False           # ä¿å­˜æµ‹è¯•ç»“æžœ
        self.save_txt = False           # ä¿å­˜æ ‡ç­¾(txt)æ–‡ä»¶
        self.iou_thres = 0.45           # iou é˜ˆå€¼
        self.conf_thres = 0.25          # ç½®ä¿¡åº¦é˜ˆå€¼
        self.speed_thres = 10           # å»¶è¿Ÿï¼Œæ¯«ç§’
        self.labels_dict = {}           # è¿”å›žç»“æžœå­—å…¸
        self.progress_value = 0         # è¿›åº¦æ¡å€¼

        # å±žæ€§åˆå§‹åŒ–
        self.model = None
        self.data = self.args.data  # data_dict
        self.imgsz = None
        self.device = None
        self.dataset = None
        self.vid_path, self.vid_writer = None, None    # è§†é¢‘è·¯å¾„å’Œè§†é¢‘å†™å…¥å™¨
        self.annotator = None
        self.data_path = None
        self.source_type = None
        self.batch = None
        self.callbacks = defaultdict(list, callbacks.default_callbacks)  # add callbacks
        # å›žè°ƒå‡½æ•°ï¼šself.callbacks åˆå§‹åŒ–ä¸ºä¸€ä¸ª defaultdictï¼Œé»˜è®¤å€¼ä¸º listï¼Œ
        # å¹¶ä¸”ä½¿ç”¨ callbacks.default_callbacks è¿›è¡Œåˆå§‹åŒ–ã€‚å›žè°ƒå‡½æ•°ç”¨äºŽåœ¨æŸäº›äº‹ä»¶å‘ç”Ÿæ—¶æ‰§è¡Œç‰¹å®šçš„æ“ä½œã€‚
        callbacks.add_integration_callbacks(self)
        # æ·»åŠ é›†æˆå›žè°ƒï¼šè°ƒç”¨ callbacks.add_integration_callbacks(self) æ–¹æ³•ï¼Œ
        # ä¸º selfï¼ˆå³å½“å‰çš„ YoloPredictor å®žä¾‹ï¼‰æ·»åŠ ä¸€äº›é»˜è®¤çš„é›†æˆå›žè°ƒå‡½æ•°ã€‚
        # è¿™äº›å›žè°ƒå‡½æ•°å¯ä»¥åœ¨ç‰¹å®šçš„äº‹ä»¶ï¼ˆå¦‚æ¨¡åž‹æŽ¨ç†ã€æ•°æ®å¤„ç†ç­‰ï¼‰å‘ç”Ÿæ—¶è¢«è°ƒç”¨ã€‚

    # main for detect
    @smart_inference_mode()
    def run(self):
        try:
            if self.args.verbose:
                LOGGER.info('')

            # è®¾ç½®æ¨¡åž‹ï¼šå‘é€åŠ è½½æ¨¡åž‹çŠ¶æ€æ¶ˆæ¯ã€‚å¦‚æžœå°šæœªåŠ è½½æ¨¡åž‹ï¼Œåˆ™è°ƒç”¨ setup_model ï¼ˆYOLOV8ï¼‰æ–¹æ³•åŠ è½½æ–°æ¨¡åž‹ï¼Œå¹¶æ›´æ–° used_model_nameã€‚
            self.yolo2main_status_msg.emit('Loding Model...')
            if not self.model:
                self.setup_model(self.new_model_name)
                self.used_model_name = self.new_model_name

            # è®¾ç½®è¾“å…¥æºï¼šè°ƒç”¨ setup_source æ–¹æ³•è®¾ç½®æ•°æ®æº
            self.setup_source(self.source if self.source is not None else self.args.source)

            # æ£€æŸ¥ä¿å­˜è·¯å¾„å’Œæ ‡ç­¾ï¼šå¦‚æžœéœ€è¦ä¿å­˜ç»“æžœæˆ–æ ‡ç­¾æ–‡ä»¶ï¼Œåˆ™åˆ›å»ºç›¸åº”ç›®å½•ã€‚
            if self.save_res or self.save_txt:
                (self.save_dir / 'labels' if self.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)

            # æ¨¡åž‹é¢„çƒ­ï¼šå¦‚æžœå°šæœªé¢„çƒ­æ¨¡åž‹ï¼Œè°ƒç”¨ warmup æ–¹æ³•è¿›è¡Œé¢„çƒ­ï¼Œå¹¶è®¾ç½® done_warmup ä¸º Trueã€‚
            if not self.done_warmup:
                self.model.warmup(imgsz=(1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))
                self.done_warmup = True

            self.seen, self.windows, self.dt, self.batch = 0, [], (ops.Profile(), ops.Profile(), ops.Profile()), None
            # åˆå§‹åŒ–ï¼šåˆå§‹åŒ–ä¸€äº›å˜é‡ï¼ŒåŒ…æ‹¬å·²å¤„ç†çš„å¸§æ•°ã€çª—å£åˆ—è¡¨ã€è®¡æ—¶å™¨ï¼ˆç”¨äºŽè®°å½•ä¸åŒé˜¶æ®µçš„è€—æ—¶ï¼‰ï¼Œä»¥åŠæ‰¹å¤„ç†å˜é‡ã€‚

            # å‡†å¤‡å¼€å§‹ç›®æ ‡æ£€æµ‹
            # for batch in self.dataset:

            # åˆå§‹åŒ–è®¡æ•°å’Œæ—¶é—´ï¼šåˆå§‹åŒ–å¸§è®¡æ•°å™¨ count å’Œèµ·å§‹æ—¶é—´ start_timeï¼Œå¹¶å°†æ•°æ®é›†è½¬æ¢ä¸ºè¿­ä»£å™¨ã€‚
            count = 0                       # run location frame
            start_time = time.time()        # used to calculate the frame rate
            batch = iter(self.dataset)
            while True:
                # ç»ˆæ­¢æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦ç»ˆæ­¢æ£€æµ‹ï¼Œå¦‚æžœéœ€è¦ï¼Œé‡Šæ”¾è§†é¢‘å†™å…¥å™¨å¹¶å‘é€ç»ˆæ­¢æ¶ˆæ¯ã€‚
                if self.stop_dtc:
                    if isinstance(self.vid_writer[-1], cv2.VideoWriter):
                        self.vid_writer[-1].release()  # release final video writer
                    self.yolo2main_status_msg.emit('Detection terminated!')
                    break
                
                # ä¸­é€”æ›´æ”¹æ¨¡åž‹ï¼šå¦‚æžœæ£€æµ‹åˆ°æ¨¡åž‹æ›´æ”¹ï¼Œåˆ™é‡æ–°è®¾ç½®æ¨¡åž‹å¹¶æ›´æ–° used_model_nameã€‚
                if self.used_model_name != self.new_model_name:  
                    # self.yolo2main_status_msg.emit('Change Model...')
                    self.setup_model(self.new_model_name)
                    self.used_model_name = self.new_model_name
                
                # æš‚åœå¼€å…³ï¼šæ£€æŸ¥æ˜¯å¦æš‚åœï¼Œå¦‚æžœæ²¡æœ‰æš‚åœï¼Œå‘é€æ£€æµ‹ä¸­æ¶ˆæ¯ï¼Œå¹¶èŽ·å–ä¸‹ä¸€æ‰¹æ•°æ®ã€‚
                if self.continue_dtc:
                    # time.sleep(0.001)
                    self.yolo2main_status_msg.emit('Detecting...')
                    batch = next(self.dataset)  # next data

                    self.batch = batch
                    path, im, im0s, vid_cap, s = batch
                    visualize = increment_path(self.save_dir / Path(path).stem, mkdir=True) if self.args.visualize else False

                    # æ‰¹å¤„ç†æ•°æ®ï¼šå¤„ç†æ‰¹æ•°æ®ï¼ŒåŒ…æ‹¬è·¯å¾„ã€å›¾åƒã€åŽŸå§‹å›¾åƒã€è§†é¢‘æ•èŽ·å¯¹è±¡ç­‰ã€‚æ ¹æ®éœ€è¦è®¾ç½®å¯è§†åŒ–è·¯å¾„ã€‚
                    count += 1              # frame count +1
                    if vid_cap:
                        all_count = vid_cap.get(cv2.CAP_PROP_FRAME_COUNT)   # èŽ·å–è§†é¢‘æ–‡ä»¶æ€»å¸§æ•°
                    else:
                        all_count = 1
                    self.progress_value = int(count/all_count*1000)         # progress bar(0~1000) è®¡ç®—å¤„ç†è¿›åº¦å¹¶æ›´æ–°è¿›åº¦æ¡
                    if count % 5 == 0 and count >= 5:                     # æ²¡5å¸§è®¡ç®—å¹¶å‘é€å¸§çŽ‡ä¿¡æ¯
                        self.yolo2main_fps.emit(str(int(5/(time.time()-start_time))))
                        start_time = time.time()                        # æ›´æ–°å¼€å§‹å¤„ç†æ—¶é—´
                    
                    # preprocess é¢„å¤„ç†
                    with self.dt[0]:
                        im = self.preprocess(im)
                        if len(im.shape) == 3:
                            im = im[None]  # expand for batch dim
                    # inference æŽ¨ç†
                    with self.dt[1]:
                        preds = self.model(im, augment=self.args.augment, visualize=visualize)
                    # postprocess åŽå¤„ç†
                    with self.dt[2]:
                        self.results = self.postprocess(preds, im, im0s)
                    # æŒ‰é¡ºåºæ‰§è¡Œå¹¶è®¡æ—¶
                    # å¯è§†åŒ–ã€ä¿å­˜å’Œå†™å…¥ç»“æžœï¼šå¾ªçŽ¯å¤„ç†æ¯å¼ å›¾åƒï¼Œè®¡ç®—é¢„å¤„ç†ã€æŽ¨ç†å’ŒåŽå¤„ç†çš„é€Ÿåº¦ï¼Œå¹¶èŽ·å–è·¯å¾„å’ŒåŽŸå§‹å›¾åƒã€‚
                    n = len(im)     # To be improved: support multiple img
                    for i in range(n):
                        self.results[i].speed = {
                            'preprocess': self.dt[0].dt * 1E3 / n,
                            'inference': self.dt[1].dt * 1E3 / n,
                            'postprocess': self.dt[2].dt * 1E3 / n}
                        p, im0 = (path[i], im0s[i].copy()) if self.source_type.webcam or self.source_type.from_img \
                            else (path, im0s.copy())
                        p = Path(p)     # the source dir

                        # s:::   video 1/1 (6/6557) 'path':
                        # must, to get boxs\labels
                        label_str = self.write_results(i, self.results, (p, im, im0))   # labels   /// original :s += 
                        
                        # labels and nums dict
                        class_nums = 0
                        target_nums = 0
                        self.labels_dict = {}
                        if 'no detections' in label_str:
                            pass
                        else:
                            for ii in label_str.split(',')[:-1]:
                                nums, label_name = ii.split('~')
                                self.labels_dict[label_name] = int(nums)
                                target_nums += int(nums)
                                class_nums += 1
                        # æ ‡ç­¾å’Œæ•°é‡å­—å…¸ï¼šå†™å…¥ç»“æžœå¹¶è§£æžæ ‡ç­¾å­—ç¬¦ä¸²ï¼Œç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„ç›®æ ‡æ•°é‡ï¼Œå¹¶æ›´æ–°æ ‡ç­¾å­—å…¸

                        # ä¿å­˜å’Œå‘é€ç»“æžœï¼šæ ¹æ®éœ€è¦ä¿å­˜å›¾åƒæˆ–è§†é¢‘ç»“æžœï¼Œå¹¶å‘é€æ£€æµ‹åŽçš„å›¾åƒã€æ£€æµ‹å‰çš„å›¾åƒã€ç±»åˆ«æ•°é‡å’Œç›®æ ‡æ•°é‡ã€‚
                        # å¦‚æžœè®¾ç½®äº†é€Ÿåº¦é˜ˆå€¼ï¼Œåˆ™å»¶è¿Ÿç›¸åº”æ—¶é—´ã€‚
                        # save img or video result
                        if self.save_res:
                            self.save_preds(vid_cap, i, str(self.save_dir / p.name))

                        # æ£€æµ‹å®Œæˆï¼šæ£€æŸ¥æ˜¯å¦å·²å¤„ç†æ‰€æœ‰å¸§ï¼Œå¦‚æžœæ˜¯ï¼Œé‡Šæ”¾è§†é¢‘å†™å…¥å™¨å¹¶å‘é€æ£€æµ‹å®Œæˆæ¶ˆæ¯ã€‚
                        self.yolo2main_res_img.emit(im0) # after detection
                        self.yolo2main_pre_img.emit(im0s if isinstance(im0s, np.ndarray) else im0s[0])   # Before testing
                        # self.yolo2main_labels.emit(self.labels_dict)        # webcam need to change the def write_results
                        self.yolo2main_class_num.emit(class_nums)
                        self.yolo2main_target_num.emit(target_nums)

                        if self.speed_thres != 0:
                            time.sleep(self.speed_thres/1000)   # delay , ms

                    self.yolo2main_progress.emit(self.progress_value)   # progress bar

                # Detection completed
                if count + 1 >= all_count:
                    if isinstance(self.vid_writer[-1], cv2.VideoWriter):
                        self.vid_writer[-1].release()  # é‡Šæ”¾è§†é¢‘å†™å…¥
                    self.yolo2main_status_msg.emit('Detection completed')
                    break

        except Exception as e:
            pass
            print(e)
            self.yolo2main_status_msg.emit('%s' % e)
        # æ•æ‰å¼‚å¸¸ï¼Œä½†æ˜¯ å‘ç”Ÿå¼‚å¸¸ä¼šå¿½ç•¥å¼‚å¸¸ï¼Œé€šè¿‡ä¿¡å·æŠŠå¼‚å¸¸ä¿¡æ¯å‘é€å‡ºåŽ»


    def get_annotator(self, img):
        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))
    # å¼€å§‹ç»˜åˆ¶ line_width è®¾ç½®äº†çº¿æ¡çš„åŽšåº¦ example æ¥è‡ªæ¨¡åž‹çš„æ³¨é‡Šç±»åˆ«çš„åç§°

    def preprocess(self, img):
        img = torch.from_numpy(img).to(self.model.device)
        # è¿™ä¸ªæ–¹æ³•å°†å›¾åƒä»Ž NumPy æ•°ç»„è½¬æ¢ä¸º PyTorch å¼ é‡ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ°æ¨¡åž‹çš„è®¾å¤‡ä¸Šã€‚
        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32
        # å¦‚æžœæ¨¡åž‹ä½¿ç”¨ fp16ï¼ˆåŠç²¾åº¦æµ®ç‚¹æ•°ï¼‰ï¼Œåˆ™å°†å›¾åƒè½¬æ¢ä¸º fp16ï¼Œå¦åˆ™è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼ˆfp32ï¼‰ã€‚
        img /= 255  # å°†åƒç´ å€¼ä»Ž 0-255 å½’ä¸€åŒ–åˆ° 0.0-1.0 çš„èŒƒå›´ã€‚
        return img


    def postprocess(self, preds, img, orig_img):
        ### important å¯¹é¢„æµ‹ç»“æžœè¿›è¡ŒåŽå¤„ç†
        # é¦–å…ˆä½¿ç”¨éžæžå¤§å€¼æŠ‘åˆ¶ï¼ˆNon-Max Suppressionï¼‰æ¥è¿‡æ»¤é‡å çš„æ£€æµ‹æ¡†ã€‚
        preds = ops.non_max_suppression(preds,
                                        self.conf_thres,
                                        self.iou_thres,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det,
                                        classes=self.args.classes)

        results = []
        for i, pred in enumerate(preds):
            orig_img = orig_img[i] if isinstance(orig_img, list) else orig_img          # å¦‚æžœ orig_img æ˜¯åˆ—è¡¨ï¼Œåˆ™å–å‡ºå¯¹åº”çš„åŽŸå§‹å›¾åƒã€‚
            shape = orig_img.shape
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()
            path, _, _, _, _ = self.batch
            img_path = path[i] if isinstance(path, list) else path      # ä»Žæ‰¹å¤„ç†è·¯å¾„ä¸­èŽ·å–å›¾åƒè·¯å¾„ã€‚
            results.append(Results(orig_img=orig_img, path=img_path, names=self.model.names, boxes=pred))
            # åˆ›å»ºä¸€ä¸ª Results å¯¹è±¡ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°ç»“æžœåˆ—è¡¨ä¸­ã€‚
        # print(results)
        return results

    def write_results(self, idx, results, batch):
        p, im, im0 = batch
        log_string = ''
        if len(im.shape) == 3:
            im = im[None]  # expand for batch dim
        self.seen += 1
        imc = im0.copy() if self.args.save_crop else im0
        if self.source_type.webcam or self.source_type.from_img:  # batch_size >= 1         # attention
            log_string += f'{idx}: '
            frame = self.dataset.count
        else:
            frame = getattr(self.dataset, 'frame', 0)
        self.data_path = p
        self.txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if self.dataset.mode == 'image' else f'_{frame}')
        # log_string += '%gx%g ' % im.shape[2:]         # !!! don't add img size~
        self.annotator = self.get_annotator(im0)

        det = results[idx].boxes  # TODO: make boxes inherit from tensors

        if len(det) == 0:
            return f'{log_string}(no detections), ' # if no, send this~~

        for c in det.cls.unique():
            n = (det.cls == c).sum()  # detections per class
            log_string += f"{n}~{self.model.names[int(c)]},"   #   {'s' * (n > 1)}, "   # don't add 's'
        # now log_string is the classes ðŸ‘†


        # write
        for d in reversed(det):
            cls, conf = d.cls.squeeze(), d.conf.squeeze()
            # å¦‚æžœ self.save_txt ä¸ºçœŸï¼Œåˆ™å°†æ£€æµ‹ç»“æžœå†™å…¥åˆ° self.txt_path.txt æ–‡ä»¶ä¸­ã€‚å†™å…¥çš„å†…å®¹åŒ…æ‹¬ç±»åˆ«ã€è¾¹ç•Œæ¡†åæ ‡ï¼ˆå¦‚æžœæœ‰éœ€è¦ï¼Œè¿˜åŒ…æ‹¬ç½®ä¿¡åº¦ï¼‰ã€‚
            if self.save_txt:  # Write to file
                line = (cls, *(d.xywhn.view(-1).tolist()), conf) \
                    if self.args.save_conf else (cls, *(d.xywhn.view(-1).tolist()))  # label format
                with open(f'{self.txt_path}.txt', 'a') as f:
                    f.write(('%g ' * len(line)).rstrip() % line + '\n')
            # å¦‚æžœéœ€è¦ä¿å­˜ç»“æžœå›¾åƒï¼ˆç”± self.save_resã€self.args.save_cropã€self.args.show æˆ– True æŽ§åˆ¶ï¼‰ï¼Œ
            # åˆ™åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†ï¼Œå¹¶å¯èƒ½æ·»åŠ å…¶ä»–æ³¨é‡Šï¼ˆå¦‚ç±»åˆ«åç§°å’ŒIDï¼‰ã€‚ä½†è¯·æ³¨æ„ï¼Œæ­¤éƒ¨åˆ†çš„ä»£ç åœ¨æä¾›çš„ä»£ç ç‰‡æ®µä¸­è¢«æˆªæ–­äº†ã€‚
            if self.save_res or self.args.save_crop or self.args.show or True:  # Add bbox to image(must)
                c = int(cls)  # integer class
                name = f'id:{int(d.id.item())} {self.model.names[c]}' if d.id is not None else self.model.names[c]
                label = None if self.args.hide_labels else (name if self.args.hide_conf else f'{name} {conf:.2f}')
                self.annotator.box_label(d.xyxy.squeeze(), label, color=colors(c, True))
            if self.args.save_crop:
                save_one_box(d.xyxy,
                             imc,
                             file=self.save_dir / 'crops' / self.model.model.names[c] / f'{self.data_path.stem}.jpg',
                             BGR=True)

        return log_string
        


class MainWindow(QMainWindow, Ui_MainWindow):
    main2yolo_begin_sgl = Signal()  # The main window sends an execution signal to the yolo instance
    def __init__(self, parent=None):
        super(MainWindow, self).__init__(parent)
        # basic interface
        self.setupUi(self)
        self.setAttribute(Qt.WA_TranslucentBackground)  # rounded transparent
        self.setWindowFlags(Qt.FramelessWindowHint)  # Set window flag: hide window borders
        UIFuncitons.uiDefinitions(self)
        # Show module shadows
        UIFuncitons.shadow_style(self, self.Class_QF, QColor(162,129,247))
        UIFuncitons.shadow_style(self, self.Target_QF, QColor(251, 157, 139))
        UIFuncitons.shadow_style(self, self.Fps_QF, QColor(170, 128, 213))
        UIFuncitons.shadow_style(self, self.Model_QF, QColor(64, 186, 193))
        


        # read model folder
        self.pt_list = os.listdir('./models')
        self.pt_list = [file for file in self.pt_list if file.endswith('.pt')]
        self.pt_list.sort(key=lambda x: os.path.getsize('./models/' + x))   # sort by file size
        self.model_box.clear()
        self.model_box.addItems(self.pt_list)
        self.Qtimer_ModelBox = QTimer(self)     # Timer: Monitor model file changes every 2 seconds
        self.Qtimer_ModelBox.timeout.connect(self.ModelBoxRefre)
        self.Qtimer_ModelBox.start(2000)

        # Yolo-v8 thread
        self.yolo_predict = YoloPredictor()                           # Create a Yolo instance
        self.select_model = self.model_box.currentText()                   # default model
        self.yolo_predict.new_model_name = "./models/%s" % self.select_model  
        self.yolo_thread = QThread()                                  # Create yolo thread
        self.yolo_predict.yolo2main_pre_img.connect(lambda x: self.show_image(x, self.pre_video)) 
        self.yolo_predict.yolo2main_res_img.connect(lambda x: self.show_image(x, self.res_video))
        self.yolo_predict.yolo2main_status_msg.connect(lambda x: self.show_status(x))             
        self.yolo_predict.yolo2main_fps.connect(lambda x: self.fps_label.setText(x))              
        # self.yolo_predict.yolo2main_labels.connect(self.show_labels)                            
        self.yolo_predict.yolo2main_class_num.connect(lambda x:self.Class_num.setText(str(x)))         
        self.yolo_predict.yolo2main_target_num.connect(lambda x:self.Target_num.setText(str(x)))       
        self.yolo_predict.yolo2main_progress.connect(lambda x: self.progress_bar.setValue(x))     
        self.main2yolo_begin_sgl.connect(self.yolo_predict.run)     
        self.yolo_predict.moveToThread(self.yolo_thread)              

        # Model parameters
        self.model_box.currentTextChanged.connect(self.change_model)     
        self.iou_spinbox.valueChanged.connect(lambda x:self.change_val(x, 'iou_spinbox'))    # iou box
        self.iou_slider.valueChanged.connect(lambda x:self.change_val(x, 'iou_slider'))      # iou scroll bar
        self.conf_spinbox.valueChanged.connect(lambda x:self.change_val(x, 'conf_spinbox'))  # conf box
        self.conf_slider.valueChanged.connect(lambda x:self.change_val(x, 'conf_slider'))    # conf scroll bar
        self.speed_spinbox.valueChanged.connect(lambda x:self.change_val(x, 'speed_spinbox'))# speed box
        self.speed_slider.valueChanged.connect(lambda x:self.change_val(x, 'speed_slider    '))  # speed scroll bar

        # Prompt window initialization
        self.Class_num.setText('--')
        self.Target_num.setText('--')
        self.fps_label.setText('--')
        self.Model_name.setText(self.select_model)
        
        # é€‰æ‹©æ£€æµ‹æº
        self.src_file_button.clicked.connect(self.open_src_file)  # select local file
        # self.src_cam_button.clicked.connect(self.show_status("The function has not yet been implemented."))#chose_cam
        # self.src_rtsp_button.clicked.connect(self.show_status("The function has not yet been implemented."))#chose_rtsp

        # å¼€å§‹æµ‹è¯•æŒ‰é’®
        self.run_button.clicked.connect(self.run_or_continue)   # pause/start
        self.stop_button.clicked.connect(self.stop)             # termination

        # å…¶ä»–å‡½æ•°æŒ‰é’®
        self.save_res_button.toggled.connect(self.is_save_res)  # save image option
        self.save_txt_button.toggled.connect(self.is_save_txt)  # Save label option
        self.ToggleBotton.clicked.connect(lambda: UIFuncitons.toggleMenu(self, True))   # left navigation button
        self.settings_button.clicked.connect(lambda: UIFuncitons.settingBox(self, True))   # top right settings button
        
        # initialization
        self.load_config()

    # The main window displays the original image and detection results
    @staticmethod
    def show_image(img_src, label):
        try:
            ih, iw, _ = img_src.shape
            w = label.geometry().width()
            h = label.geometry().height()
            # keep the original data ratio
            if iw/w > ih/h:
                scal = w / iw
                nw = w
                nh = int(scal * ih)
                img_src_ = cv2.resize(img_src, (nw, nh))

            else:
                scal = h / ih
                nw = int(scal * iw)
                nh = h
                img_src_ = cv2.resize(img_src, (nw, nh))

            # é¢œè‰²ç©ºé—´è½¬æ¢
            frame = cv2.cvtColor(img_src_, cv2.COLOR_BGR2RGB)
            # æŠŠopencvå›¾åƒè½¬æ¢æˆQTå›¾åƒ
            img = QImage(frame.data, frame.shape[1], frame.shape[0], frame.shape[2] * frame.shape[1],
                         QImage.Format_RGB888)
            # å†æ ‡ç­¾ä¸Šæ˜¾ç¤ºå›¾åƒ
            label.setPixmap(QPixmap.fromImage(img))

        except Exception as e:
            print(repr(e))

    # Control start/pause
    def run_or_continue(self):
        if self.yolo_predict.source == '':
            self.show_status('Please select a video source before starting detection...')
            self.run_button.setChecked(False)
        else:
            self.yolo_predict.stop_dtc = False
            if self.run_button.isChecked():
                self.run_button.setChecked(True)    # start button
                self.save_txt_button.setEnabled(False)  # It is forbidden to check and save after starting the detection
                self.save_res_button.setEnabled(False)
                self.show_status('Detecting...')           
                self.yolo_predict.continue_dtc = True   # Control whether Yolo is paused
                if not self.yolo_thread.isRunning():
                    self.yolo_thread.start()
                    self.main2yolo_begin_sgl.emit()

            else:
                self.yolo_predict.continue_dtc = False
                self.show_status("Pause...")
                self.run_button.setChecked(False)    # start button

    # bottom status bar information
    def show_status(self, msg):
        self.status_bar.setText(msg)
        if msg == 'Detection completed' or msg == 'æ£€æµ‹å®Œæˆ':
            self.save_res_button.setEnabled(True)
            self.save_txt_button.setEnabled(True)
            self.run_button.setChecked(False)    
            self.progress_bar.setValue(0)
            if self.yolo_thread.isRunning():
                self.yolo_thread.quit()         # end process
        elif msg == 'Detection terminated!' or msg == 'æ£€æµ‹ç»ˆæ­¢':
            self.save_res_button.setEnabled(True)
            self.save_txt_button.setEnabled(True)
            self.run_button.setChecked(False)    
            self.progress_bar.setValue(0)
            if self.yolo_thread.isRunning():
                self.yolo_thread.quit()         # end process
            self.pre_video.clear()           # clear image display  
            self.res_video.clear()          
            self.Class_num.setText('--')
            self.Target_num.setText('--')
            self.fps_label.setText('--')

    # select local file
    def open_src_file(self):
        config_file = 'config/fold.json'    
        config = json.load(open(config_file, 'r', encoding='utf-8'))
        open_fold = config['open_fold']     
        if not os.path.exists(open_fold):
            open_fold = os.getcwd()
        name, _ = QFileDialog.getOpenFileName(self, 'Video/image', open_fold, "Pic File(*.mp4 *.mkv *.avi *.flv *.jpg *.png)")
        if name:
            self.yolo_predict.source = name
            self.show_status('Load Fileï¼š{}'.format(os.path.basename(name))) 
            config['open_fold'] = os.path.dirname(name)
            config_json = json.dumps(config, ensure_ascii=False, indent=2)  
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(config_json)
            self.stop()


    def is_save_res(self):
        if self.save_res_button.checkState() == Qt.CheckState.Unchecked:
            self.show_status('NOTE: Run image results are not saved.')
            self.yolo_predict.save_res = False
        elif self.save_res_button.checkState() == Qt.CheckState.Checked:
            self.show_status('NOTE: Run image results will be saved.')
            self.yolo_predict.save_res = True
    
    # Save test result button -- label (txt)
    def is_save_txt(self):
        if self.save_txt_button.checkState() == Qt.CheckState.Unchecked:
            self.show_status('NOTE: Labels results are not saved.')
            self.yolo_predict.save_txt = False
        elif self.save_txt_button.checkState() == Qt.CheckState.Checked:
            self.show_status('NOTE: Labels results will be saved.')
            self.yolo_predict.save_txt = True

    # Configuration initialization  ~~~wait to change~~~
    def load_config(self):
        # åˆå§‹åŒ– æ£€æµ‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ å¦‚æžœä¸å­˜åœ¨ å°± é‡æ–°åˆ›å»º
        config_file = 'config/setting.json'
        if not os.path.exists(config_file):
            iou = 0.26
            conf = 0.33   
            rate = 10
            save_res = 0   
            save_txt = 0    
            new_config = {"iou": iou,
                          "conf": conf,
                          "rate": rate,
                          "save_res": save_res,
                          "save_txt": save_txt
                          }
            new_json = json.dumps(new_config, ensure_ascii=False, indent=2)
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(new_json)
        else:
            config = json.load(open(config_file, 'r', encoding='utf-8'))
            if len(config) != 5:
                iou = 0.26
                conf = 0.33
                rate = 10
                save_res = 0
                save_txt = 0
            else:
                iou = config['iou']
                conf = config['conf']
                rate = config['rate']
                save_res = config['save_res']
                save_txt = config['save_txt']
        self.save_res_button.setCheckState(Qt.CheckState(save_res))
        self.yolo_predict.save_res = (False if save_res==0 else True )
        self.save_txt_button.setCheckState(Qt.CheckState(save_txt)) 
        self.yolo_predict.save_txt = (False if save_txt==0 else True )
        self.run_button.setChecked(False)  
        self.show_status("Welcome~")

    # Terminate button and associated state
    def stop(self):
        if self.yolo_thread.isRunning():
            self.yolo_thread.quit()         # end thread
        self.yolo_predict.stop_dtc = True
        self.run_button.setChecked(False)    # start key recovery
        self.save_res_button.setEnabled(True)   # Ability to use the save button
        self.save_txt_button.setEnabled(True)   # Ability to use the save button
        self.pre_video.clear()           # clear image display
        self.res_video.clear()           # clear image display
        self.progress_bar.setValue(0)
        self.Class_num.setText('--')
        self.Target_num.setText('--')
        self.fps_label.setText('--')

    # Change detection parameters
    def change_val(self, x, flag):
        if flag == 'iou_spinbox':
            self.iou_slider.setValue(int(x*100))    # The box value changes, changing the slider
        elif flag == 'iou_slider':
            self.iou_spinbox.setValue(x/100)        # The slider value changes, changing the box
            self.show_status('IOU Threshold: %s' % str(x/100))
            self.yolo_predict.iou_thres = x/100
        elif flag == 'conf_spinbox':
            self.conf_slider.setValue(int(x*100))
        elif flag == 'conf_slider':
            self.conf_spinbox.setValue(x/100)
            self.show_status('Conf Threshold: %s' % str(x/100))
            self.yolo_predict.conf_thres = x/100
        elif flag == 'speed_spinbox':
            self.speed_slider.setValue(x)
        elif flag == 'speed_slider':
            self.speed_spinbox.setValue(x)
            self.show_status('Delay: %s ms' % str(x))
            self.yolo_predict.speed_thres = x  # ms
            
    # change model
    def change_model(self,x):
        self.select_model = self.model_box.currentText()
        self.yolo_predict.new_model_name = "./models/%s" % self.select_model
        self.show_status('Change Modelï¼š%s' % self.select_model)
        self.Model_name.setText(self.select_model)

    # label result
    # def show_labels(self, labels_dic):
    #     try:
    #         self.result_label.clear()
    #         labels_dic = sorted(labels_dic.items(), key=lambda x: x[1], reverse=True)
    #         labels_dic = [i for i in labels_dic if i[1]>0]
    #         result = [' '+str(i[0]) + 'ï¼š' + str(i[1]) for i in labels_dic]
    #         self.result_label.addItems(result)
    #     except Exception as e:
    #         self.show_status(e)

    # Cycle monitoring model file changes
    def ModelBoxRefre(self):
        pt_list = os.listdir('./models')
        pt_list = [file for file in pt_list if file.endswith('.pt')]
        pt_list.sort(key=lambda x: os.path.getsize('./models/' + x))
        # It must be sorted before comparing, otherwise the list will be refreshed all the time
        if pt_list != self.pt_list:
            self.pt_list = pt_list
            self.model_box.clear()
            self.model_box.addItems(self.pt_list)

    # Get the mouse position (used to hold down the title bar and drag the window)
    def mousePressEvent(self, event):
        p = event.globalPosition()
        globalPos = p.toPoint()
        self.dragPos = globalPos

    # Optimize the adjustment when dragging the bottom and right edges of the window size
    def resizeEvent(self, event):
        # Update Size Grips
        UIFuncitons.resize_grips(self)

    # Exit Exit thread, save settings
    def closeEvent(self, event):
        config_file = 'config/setting.json'
        config = dict()
        config['iou'] = self.iou_spinbox.value()
        config['conf'] = self.conf_spinbox.value()
        config['rate'] = self.speed_spinbox.value()
        config['save_res'] = (0 if self.save_res_button.checkState()==Qt.Unchecked else 2)
        config['save_txt'] = (0 if self.save_txt_button.checkState()==Qt.Unchecked else 2)
        config_json = json.dumps(config, ensure_ascii=False, indent=2)
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(config_json)
        # Exit the process before closing
        if self.yolo_thread.isRunning():
            self.yolo_predict.stop_dtc = True
            self.yolo_thread.quit()
            MessageBox(
                self.close_button, title='Note', text='Exiting, please wait...', time=3000, auto=True).exec()
            sys.exit(0)
        else:
            sys.exit(0)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    Home = MainWindow()
    Home.show()
    sys.exit(app.exec())  
